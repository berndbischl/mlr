% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/FeatingEnsemble.R
\name{makeFeatingEnsemble}
\alias{makeFeatingEnsemble}
\title{Feature-subspace Aggregating Ensemble algorithm}
\usage{
makeFeatingEnsemble(learner, attrs, random, maximum.level, minimum.instance,
  predict.type = "response")
}
\arguments{
\item{learner}{a classification learner object}

\item{attrs}{an integer vector indicating the indices of the features taken into
tree building algorithm.}

\item{random}{an integer indicating the number of trees. All combination of trees will be
considered if set to 0 (this might be very expensive).}

\item{maximum.level}{the maximum.level of the tree, the root is level 0.}

\item{minimum.instance}{the minimum number of data instances to train a learner on each leaf.
The majority or proportion will be used as prediction otherwise.}

\item{predict.type}{either \code{response} or \code{prob} indicating the format of the prediction.}
}
\description{
An ensemble algorithm which builds local models instead of global models.
The algorithm builds several trees to split the data space then train a model on each leaf.
The final result is the aggregation of results from all the trees. The algorithm is introduced
in the paper "Feature-subspace aggregating: ensembles for stable and unstable learners" by Ting et al.
}
\examples{
data(iris)
lrn = makeLearner("classif.svm")
tsk = makeClassifTask(data = iris, target = "Species")
flrn = makeFeatingEnsemble(learner = lrn, attrs = 1:4, random = 5, maximum.level = 1,
  minimum.instance = 4, predict.type = "prob")
m = train(flrn, tsk)
pred = predict(m, newdata = iris)
}
\references{
Ting, Kai Ming, et al. "Feature-subspace aggregating: ensembles for stable and unstable learners." Machine Learning 82.3 (2011): 375-397.
}

