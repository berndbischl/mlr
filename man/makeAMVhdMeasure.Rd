% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Make_measure_AMVhd.R
\name{makeAMVhdMeasure}
\alias{makeAMVhdMeasure}
\title{Creates the measure Area under Mass-Volume Curve (AMV) for Anomaly detection (oneclass) for high dimensional data}
\usage{
makeAMVhdMeasure(id = "AMVhd", minimize = TRUE, amv.iters = 10,
  amv.feats = 3, alphas = c(0.9, 0.99), n.alpha = 50, n.sim = 1e+05,
  best = 0, worst = NULL, name = id, note = "")
}
\arguments{
\item{id}{[\code{character(1)}]\cr
Name of measure.}

\item{minimize}{[\code{logical(1)}]\cr
Should the measure be minimized?
Default is \code{TRUE}.}

\item{amv.iters}{[\code{numeric}] \cr
Number of subsamples.
Default is 10.}

\item{amv.feats}{[\code{numeric}] \cr
Number of features to be drawn in the feature subsamples.
Default is 3.}

\item{alphas}{[\code{numeric}] \cr
Numeric vector of alphas, which lies in [0, 1), representing the computed quantiles.
Default: lower quantile alpha1 = 0.9, upper quantile alpha2 = 0.99 as we are interested in the performance of the scoring function in the the low density regions.}

\item{n.alpha}{[\code{numeric}] \cr
Numeric discretization parameter greater than one, which splits the intervall of alpha1 and alpha2 as follows: {alpha1 + j * (alpha2-alpha1)/(n.alpha-1), j element of {0,...,n.alpha-1}}, Default: n.alpha = 50.}

\item{n.sim}{[\code{numeric(1)}] \cr
Number of Monte-Carlo Samples, Default is 10^4.}

\item{best}{[\code{numeric(1)}]\cr
Best obtainable value for measure.
Default is -\code{Inf} or \code{Inf}, depending on \code{minimize}.}

\item{worst}{[\code{numeric(1)}]\cr
Worst obtainable value for measure.
Default is \code{Inf} or -\code{Inf}, depending on \code{minimize}.}

\item{name}{[\code{character}] \cr
Name of the measure. Default is \code{id}.}

\item{note}{[\code{character}] \cr
Description and additional notes for the measure. Default is \dQuote{}.}
}
\value{
[\code{numeric(1)}]
  Area under Mass-Volume Curve (AMV) for high dimensional data.

[\code{\link{Measure}}].
}
\description{
Creates a measure for oneclass classification on high dimensional data
(recommend for dimension greater than 8) called AMVhd, which is based on the
Area under the Mass-Volume Curve (AMV) (see \code{makeAMVMeasure}).
The basic idea is to do several feature subsamplings (of dimension less than 8)
to reduce the dimension of the data, therefore AMV can be applied on each
subsamples, yielding partial scores AMV_k. The mean of the partial scores is
the new performancecriteria AMVhd.
}
\examples{
# creates anomaly data with feature size nine
sigma = matrix(0, 9, 9)
diag(sigma) = c(4, 5, 8, 3, 2, 6, 9, 3, 1)
normal = MASS::mvrnorm(n = 1000, rep(0, 9), sigma)
colnames(normal) = paste0("V", 1:9)
normal = as.data.frame(normal)
normal$normal = TRUE

anomaly = matrix(sample(size = 50 * 9, x = 20:100, replace = TRUE), 50, 9)
colnames(anomaly) = paste0("V", 1:9)
anomaly = as.data.frame(anomaly)
anomaly$normal = FALSE
data = rbind(normal, anomaly)
data = na.omit(data)

# create train and test sets
library(BBmisc)
inds.split = chunk(seq_len(nrow(data)), shuffle = TRUE, props = c(0.6, 0.4))
train.inds = inds.split[[1]]
test.inds = inds.split[[2]]

# creates an AMVhd measure which calculates the area under the curve between 0.8 and 0.99
# with 50 steps for high dimensional data.
AMVhd = makeAMVhdMeasure(id = "AMV", minimize = TRUE, alphas = c(0.8, 0.99),
n.alpha = 50, n.sim = 10e4, best = 0, worst = NULL)

task = makeOneClassTask(data = data, target = "normal", positive = "TRUE", negative = "FALSE")
# base learner
lrn = makeLearner("oneclass.svm", predict.type = "prob")

# for applying AMVhd we need to use the AMVhdWrapper
# wrapped learner, with 3 feature subsample for each of the 10 iteration
lrn_amww = makeAMVhdWrapper(lrn, amv.iters = 10, amv.feats = 3)
# wrapped model
mod_amww = train(lrn_amww, task, subset = train.inds)
# list all submodels, first list element is the full model
submod = getLearnerModel(mod_amww, more.unwrap = FALSE)
# wrapped prediction
pred_amww = predict(mod_amww, task, subset = test.inds)
# t contains the prediction with subsampled features
t = attr(pred_amww, "AMVhdSubpredict")

# calculate AMVhd performance
set.seed(123)
performance(pred = pred_amww, measures = list(AMVhd), model = mod_amww,
task = task, feats = data[test.inds, 1:9])
}
\references{
Nicolas, G. How to Evaluate the Quality of Unsupervised Anomaly Detection Algorithms,
arXiv preprint arXiv:1607.01152
}
\seealso{
Other performance.: \code{\link{makeAMVMeasure}},
  \code{\link{makePrecisionMeasure}},
  \code{\link{makeWACMeasure}}
}
